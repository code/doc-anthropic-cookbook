{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb718d24",
   "metadata": {},
   "source": [
    "# Automatic Context Compaction\n",
    "\n",
    "Long-running agentic tasks can often exceed context limits. Tool heavy workflows or long conversations quickly consume the token context window. In [Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), we discussed how managing context can help avoid performance degradation and context rot.\n",
    "\n",
    "The Claude Agent Python SDK can help manage this context by automatically compressing conversation history when token usage exceeds a configurable threshold, allowing tasks to continue beyond the typical 200k token context limit.\n",
    "\n",
    "In this cookbook, we'll demonstrate context compaction through an **agentic customer service workflow**. Imagine you've built an AI customer service agent tasked with processing a queue of support tickets. For each ticket, you must classify the issue, search the knowledge base, set priority, route to the appropriate team, draft a response, and mark it complete. As you process ticket after ticket, the conversation history fills with classifications, knowledge base searches, and drafted responses‚Äîquickly consuming thousands of tokens.\n",
    "\n",
    "## What is Context Compaction?\n",
    "\n",
    "When building agentic workflows with tool use, conversations can grow very large as the agent iterates on complex tasks. The `compaction_control` parameter provides automatic context management by:\n",
    "\n",
    "1. Monitoring token usage per turn in the conversation\n",
    "2. When a threshold is exceeded, injecting a summary prompt as a user turn\n",
    "3. Having the model generate a summary wrapped in `<summary></summary>` tags. These tags aren't parsed, but are there to help guide the model.\n",
    "4. Clearing the conversation history and resuming with only the summary\n",
    "5. Continuing the task with the compressed context\n",
    "\n",
    "## By the end of this cookbook, you'll be able to:\n",
    " \n",
    " - Understand how to effectively manage context limits in iterative workflows\n",
    " - Write agents that leverage automatic context compaction\n",
    " - Design workflows that maintain focus across multiple iterations\n",
    "\n",
    "##  Prerequisites\n",
    "\n",
    "Before following this guide, ensure you have:\n",
    "\n",
    "**Required Knowledge**\n",
    "\n",
    "- Basic understanding of agentic patterns and tool calling\n",
    "\n",
    "**Required Tools**\n",
    "\n",
    "Python 3.11 or higher\n",
    "Anthropic API key\n",
    "Anthropic SDK >= 0.74.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e3b52",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pedram/code/claude-cookbooks-private/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba96da5",
   "metadata": {},
   "source": [
    "Note: Ensure your .env file contains:\n",
    "\n",
    "`ANTHROPIC_API_KEY=your_key_here`\n",
    "\n",
    "Load your environment variables and configure the client. We also load a helper utility to visualize Claude message responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f6d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils.visualize import visualize\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"claude-sonnet-4-5\"\n",
    "viz = visualize(auto_show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cf8e3",
   "metadata": {},
   "source": [
    "## Setting the Stage\n",
    "\n",
    "In [utils/customer_service_tools.py](utils/customer_service_tools.py), we've defined several functions for processing customer support tickets:\n",
    "\n",
    "- `get_next_ticket()` - Retrieves the next unprocessed ticket from the queue\n",
    "- `classify_ticket(ticket_id, category)` - Categorizes issues as billing, technical, account, product, or shipping\n",
    "- `search_knowledge_base(query)` - Finds relevant help articles and solutions\n",
    "- `set_priority(ticket_id, priority)` - Assigns priority levels (low, medium, high, urgent)\n",
    "- `route_to_team(ticket_id, team)` - Routes tickets to the appropriate support team\n",
    "- `draft_response(ticket_id, response_text)` - Creates customer-facing responses\n",
    "- `mark_complete(ticket_id)` - Finalizes processed tickets\n",
    "\n",
    "For a customer service agent, these tools enable processing tickets systematically. Each ticket requires classification, research, prioritization, routing, and response drafting. When processing 20-30 tickets in sequence, the conversation history fills with tool results from every classification, every knowledge base search, and every drafted response, causing exponential token growth.\n",
    "\n",
    "We'll start by using the `beta_tool` decorator to import these functions as tools for our agent:\n",
    "\n",
    "```python\n",
    "import anthropic\n",
    "from anthropic import beta_tool\n",
    "\n",
    "@beta_tool\n",
    "def get_next_ticket() -> dict:\n",
    "    \"\"\"Retrieve the next unprocessed support ticket from the queue.\"\"\"\n",
    "    ...\n",
    "```\n",
    "\n",
    "Since our API already has the functions defined using the `beta_tool` decoractor, so we can import them and use them with the Claude API directly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d2a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from utils.customer_service_tools import (\n",
    "    classify_ticket,\n",
    "    draft_response,\n",
    "    get_next_ticket,\n",
    "    initialize_ticket_queue,\n",
    "    mark_complete,\n",
    "    route_to_team,\n",
    "    search_knowledge_base,\n",
    "    set_priority,\n",
    ")\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "tools = [\n",
    "    get_next_ticket,\n",
    "    classify_ticket,\n",
    "    search_knowledge_base,\n",
    "    set_priority,\n",
    "    route_to_team,\n",
    "    draft_response,\n",
    "    mark_complete,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fecfb8",
   "metadata": {},
   "source": [
    "## Baseline: Running Without Compaction\n",
    "\n",
    "Let's start with a realistic customer service scenario: Processing a queue of support tickets. The workflow looks like this:\n",
    "\n",
    "**For Each Ticket:**\n",
    "1. Fetch the ticket using `get_next_ticket()`\n",
    "2. Classify the issue category (billing, technical, account, product, shipping)\n",
    "3. Search the knowledge base for relevant information\n",
    "4. Set appropriate priority (low, medium, high, urgent)\n",
    "5. Route to the correct team\n",
    "6. Draft a customer response\n",
    "7. Mark the ticket complete\n",
    "8. Move to the next ticket\n",
    "\n",
    "**The Challenge**: With 5 tickets in the queue, and each requiring 7 tool calls, Claude will make 35 tool calls. The results from each step including classification knowledge base search, and drafted responses accumulate in the conversation history. Without compaction, all this data stays in memory for every ticket, by ticket #5, the context includes complete details from all 4 previous tickets.\n",
    "\n",
    "Let's run this workflow **without compaction** and observe what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uef86nvtl4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn  1: Input=  1,537 tokens | Output=   57 tokens | Messages= 1 | Cumulative In=   1,537\n",
      "Turn  2: Input=  1,759 tokens | Output=  153 tokens | Messages= 3 | Cumulative In=   3,296\n",
      "Turn  3: Input=  2,221 tokens | Output=  137 tokens | Messages= 5 | Cumulative In=   5,517\n",
      "Turn  4: Input=  2,526 tokens | Output=  245 tokens | Messages= 7 | Cumulative In=   8,043\n",
      "Turn  5: Input=  2,820 tokens | Output=   58 tokens | Messages= 9 | Cumulative In=  10,863\n",
      "Turn  6: Input=  3,003 tokens | Output=   57 tokens | Messages=11 | Cumulative In=  13,866\n",
      "Turn  7: Input=  3,234 tokens | Output=  141 tokens | Messages=13 | Cumulative In=  17,100\n",
      "Turn  8: Input=  3,703 tokens | Output=  137 tokens | Messages=15 | Cumulative In=  20,803\n",
      "Turn  9: Input=  4,008 tokens | Output=  277 tokens | Messages=17 | Cumulative In=  24,811\n",
      "Turn 10: Input=  4,334 tokens | Output=   58 tokens | Messages=19 | Cumulative In=  29,145\n",
      "Turn 11: Input=  4,516 tokens | Output=   56 tokens | Messages=21 | Cumulative In=  33,661\n",
      "Turn 12: Input=  4,750 tokens | Output=  144 tokens | Messages=23 | Cumulative In=  38,411\n",
      "Turn 13: Input=  5,345 tokens | Output=  137 tokens | Messages=25 | Cumulative In=  43,756\n",
      "Turn 14: Input=  5,650 tokens | Output=  344 tokens | Messages=27 | Cumulative In=  49,406\n",
      "Turn 15: Input=  6,044 tokens | Output=   58 tokens | Messages=29 | Cumulative In=  55,450\n",
      "Turn 16: Input=  6,226 tokens | Output=   56 tokens | Messages=31 | Cumulative In=  61,676\n",
      "Turn 17: Input=  6,450 tokens | Output=  141 tokens | Messages=33 | Cumulative In=  68,126\n",
      "Turn 18: Input=  6,919 tokens | Output=  137 tokens | Messages=35 | Cumulative In=  75,045\n",
      "Turn 19: Input=  7,224 tokens | Output=  323 tokens | Messages=37 | Cumulative In=  82,269\n",
      "Turn 20: Input=  7,597 tokens | Output=   58 tokens | Messages=39 | Cumulative In=  89,866\n",
      "Turn 21: Input=  7,781 tokens | Output=   62 tokens | Messages=41 | Cumulative In=  97,647\n",
      "Turn 22: Input=  8,011 tokens | Output=  145 tokens | Messages=43 | Cumulative In= 105,658\n",
      "Turn 23: Input=  8,484 tokens | Output=  137 tokens | Messages=45 | Cumulative In= 114,142\n",
      "Turn 24: Input=  8,789 tokens | Output=  323 tokens | Messages=47 | Cumulative In= 122,931\n",
      "Turn 25: Input=  9,162 tokens | Output=   58 tokens | Messages=49 | Cumulative In= 132,093\n",
      "Turn 26: Input=  9,346 tokens | Output=   63 tokens | Messages=51 | Cumulative In= 141,439\n",
      "Turn 27: Input=  9,442 tokens | Output=  340 tokens | Messages=53 | Cumulative In= 150,881\n",
      "\n",
      "============================================================\n",
      "BASELINE RESULTS (NO COMPACTION)\n",
      "============================================================\n",
      "Total turns:   27\n",
      "Input tokens:  150,881\n",
      "Output tokens: 3,902\n",
      "Total tokens:  154,783\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from anthropic.types.beta import BetaMessageParam\n",
    "\n",
    "num_tickets = 5\n",
    "initialize_ticket_queue(num_tickets)\n",
    "\n",
    "messages: list[BetaMessageParam] = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are an AI customer service agent. Your task is to process support tickets from a queue.\n",
    "\n",
    "For EACH ticket, you must complete ALL these steps:\n",
    "\n",
    "1. **Fetch ticket**: Call get_next_ticket() to retrieve the next unprocessed ticket\n",
    "2. **Classify**: Call classify_ticket() to categorize the issue (billing/technical/account/product/shipping)\n",
    "3. **Research**: Call search_knowledge_base() to find relevant information for this ticket type\n",
    "4. **Prioritize**: Call set_priority() to assign priority (low/medium/high/urgent) based on severity\n",
    "5. **Route**: Call route_to_team() to assign to the appropriate team\n",
    "6. **Draft**: Call draft_response() to create a helpful customer response using KB information\n",
    "7. **Complete**: Call mark_complete() to finalize this ticket\n",
    "8. **Continue**: Immediately fetch the next ticket and repeat\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Process tickets ONE AT A TIME in sequence\n",
    "- Complete ALL 7 steps for each ticket before moving to the next\n",
    "- Keep fetching and processing tickets until you get an error that the queue is empty\n",
    "- There are {num_tickets} tickets total - process all of them\n",
    "- Be thorough but efficient\n",
    "\n",
    "Begin by fetching the first ticket.\"\"\",\n",
    "    }\n",
    "]\n",
    "\n",
    "total_input = 0\n",
    "total_output = 0\n",
    "turn_count = 0\n",
    "\n",
    "runner = client.beta.messages.tool_runner(\n",
    "    model=MODEL,\n",
    "    max_tokens=4096,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "for message in runner:\n",
    "    turn_count += 1\n",
    "    total_input += message.usage.input_tokens\n",
    "    total_output += message.usage.output_tokens\n",
    "    print(\n",
    "            f\"Turn {turn_count:2d}: Input={message.usage.input_tokens:7,} tokens | \"\n",
    "            f\"Output={message.usage.output_tokens:5,} tokens | \"\n",
    "            f\"Messages={len(runner._params['messages']):2d} | \"\n",
    "            f\"Cumulative In={total_input:8,}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"BASELINE RESULTS (NO COMPACTION)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Total turns:   {turn_count}\")\n",
    "print(f\"Input tokens:  {total_input:,}\")\n",
    "print(f\"Output tokens: {total_output:,}\")\n",
    "print(f\"Total tokens:  {total_input + total_output:,}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd25c6f",
   "metadata": {},
   "source": [
    "Now that we have our baseline, we can see how token usage grows as we process more tickets. By ticket #5, the context is bloated with all previous ticket details, leading to high token consumption. Let's preview the final response from Claude after processing all tickets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b51b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect! I have successfully processed all 5 tickets in the queue. Here's a summary of what was completed:\n",
      "\n",
      "## Processing Summary\n",
      "\n",
      "**TICKET-1 - Jane Johnson** (Two-factor authentication issue)\n",
      "- Category: Account\n",
      "- Priority: High\n",
      "- Team: Account Services\n",
      "- Issue: Customer locked out due to 2FA/lost phone with backup codes not working\n",
      "\n",
      "**TICKET-2 - Alex Johnson** (Billing cycle confusion)\n",
      "- Category: Billing\n",
      "- Priority: Medium\n",
      "- Team: Billing Team\n",
      "- Issue: Confusion about billing dates (signed up 11/3 but charged 11/13)\n",
      "\n",
      "**TICKET-3 - Morgan Smith** (App crashes on startup)\n",
      "- Category: Technical\n",
      "- Priority: High\n",
      "- Team: Tech Support\n",
      "- Issue: App crashing after v4.5.1 update on iPad Pro with macOS 14.2\n",
      "\n",
      "**TICKET-4 - Jane Davis** (Payment method update error)\n",
      "- Category: Billing\n",
      "- Priority: Medium\n",
      "- Team: Billing Team\n",
      "- Issue: Unable to update credit card information - getting error message\n",
      "\n",
      "**TICKET-5 - Chris Jones** (Payment method update error)\n",
      "- Category: Billing\n",
      "- Priority: Medium\n",
      "- Team: Billing Team\n",
      "- Issue: Unable to update credit card information - getting error message\n",
      "\n",
      "All tickets have been classified, researched, prioritized, routed to appropriate teams, provided with draft responses using knowledge base information, and marked as complete. The queue is now empty.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "klok33ohsvn",
   "metadata": {},
   "source": [
    "### Understanding the Problem\n",
    "\n",
    "In the baseline workflow above, Claude had to:\n",
    "- Process **5 support tickets** sequentially\n",
    "- Complete **7 steps per ticket** (fetch, classify, research, prioritize, route, draft, complete)\n",
    "- Make **35 tool calls** with results accumulating in conversation history\n",
    "- Store **every classification, every knowledge base search, every drafted response** in memory\n",
    "\n",
    "**Why This Happens**:\n",
    "1. **Exponential token growth** - With each tool use, the entire conversation history (including all previous tool results) is sent to Claude\n",
    "2. **Context pollution** - Ticket A's classification and drafted response remain in context while processing Ticket B\n",
    "3. **Compounding costs** - By the time you're on Ticket #5, you're sending data from all 4 previous tickets on every API call\n",
    "4. **Slower responses** - Processing massive contexts takes longer\n",
    "5. **Risk of hitting limits** - Eventually you hit the 200k token context window\n",
    "\n",
    "\n",
    "**What We Actually Need**: After completing Ticket A, we only need a **brief summary** (ticket resolved, category, priority) - not the full classification result, knowledge base search, and complete drafted response. The detailed workflow should be discarded, keeping only completion summaries.\n",
    "\n",
    "Let's see how automatic context compaction solves this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "byut5h7hi3",
   "metadata": {},
   "source": [
    "## Enabling Automatic Context Compaction\n",
    "\n",
    "Now let's run the exact same customer service workflow, but with automatic context compaction enabled. We simply add the `compaction_control` parameter to our tool runner.\n",
    "\n",
    "The `compaction_control` parameter has one required field and several optional ones:\n",
    "\n",
    "- **`enabled`** (required): Boolean to turn compaction on/off\n",
    "- **`context_token_threshold`** (optional): Token count that triggers compaction (default: 100,000)\n",
    "- **`model`** (optional): Model to use for summarization (defaults to the main model)\n",
    "- **`summary_prompt`** (optional): Custom prompt for generating summaries\n",
    "\n",
    "For this customer service workflow, we'll use a **5,000 token threshold** - this means after processing several tickets (which generates classifications, KB searches, and responses), compaction will trigger. This allows Claude to:\n",
    "1. **Keep completion summaries** (tickets resolved, categories, outcomes)\n",
    "2. **Discard detailed tool results** (full KB articles, complete classifications, drafted response text)\n",
    "3. **Start fresh** when processing the next batch of tickets\n",
    "\n",
    "This mimics how a real support agent works: resolve the ticket, document it briefly, move to the next case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "x6lnx8d20fr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn  1: Input=  1,537 tokens | Output=   61 tokens | Messages= 1 | Cumulative In=   1,537\n",
      "Turn  2: Input=  1,775 tokens | Output=  154 tokens | Messages= 3 | Cumulative In=   3,312\n",
      "Turn  3: Input=  2,259 tokens | Output=  137 tokens | Messages= 5 | Cumulative In=   5,571\n",
      "Turn  4: Input=  2,564 tokens | Output=  254 tokens | Messages= 7 | Cumulative In=   8,135\n",
      "Turn  5: Input=  2,867 tokens | Output=   58 tokens | Messages= 9 | Cumulative In=  11,002\n",
      "Turn  6: Input=  3,051 tokens | Output=   56 tokens | Messages=11 | Cumulative In=  14,053\n",
      "üîÑ Compaction occurred! Messages: 11 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Objective:** Process 5 support tickets from the queue, completing all 7 steps for each ticket in sequence.\n",
      "\n",
      "**Steps Required Per Ticket:**\n",
      "1. Fetch ticket (get_next_ticket)\n",
      "2. Classify (classify_ticket)\n",
      "3. Research (search_knowledge_base)\n",
      "4. Prioritize (set_priority)\n",
      "5. Route (route_to_team)\n",
      "6. Draft response (draft_response)\n",
      "7. Mark complete (mark_complete)\n",
      "\n",
      "**Tickets Completed: 1 of 5**\n",
      "\n",
      "### TICKET-1 (COMPLETED ‚úì)\n",
      "- Customer: Jane Davis\n",
      "- Issue: Unexpected charge after subscription cancellation\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "- Action: Apologized for billing error, escalated to billing team for refund processing within 5-7 business days\n",
      "\n",
      "### TICKET-2 (IN PROGRESS)\n",
      "- Customer: Alex Jones\n",
      "- Issue: App crashes immediately after update v5.7.18 on MacBook Pro running Windows 11 (note: unusual OS combination)\n",
      "- Category: technical (already classified)\n",
      "- Status: Fetched, needs remaining 6 steps\n",
      "- **Next Steps:**\n",
      "  1. Classify as technical\n",
      "  2. Search knowledge base for technical/app crash/update issues\n",
      "  3. Set priority (likely high due to complete app failure)\n",
      "  4. Route to technical-team\n",
      "  5. Draft response with troubleshooting steps\n",
      "  6. Mark complete\n",
      "  7. Fetch TICKET-3\n",
      "\n",
      "**Remaining Tickets:** 3 more tickets to process (TICKET-3, TICKET-4, TICKET-5)\n",
      "\n",
      "**Key Learning:** Continue processing tickets sequentially, completing all 7 steps before moving to the next ticket.\n",
      "</summary>\n",
      "Turn  7: Input=  1,682 tokens | Output=  169 tokens | Messages= 1 | Cumulative In=  15,735\n",
      "Turn  8: Input=  2,302 tokens | Output=  441 tokens | Messages= 3 | Cumulative In=  18,037\n",
      "Turn  9: Input=  2,974 tokens | Output=   58 tokens | Messages= 5 | Cumulative In=  21,011\n",
      "üîÑ Compaction occurred! Messages: 5 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Objective:** Process 5 support tickets from the queue, completing all 7 steps for each ticket in sequence.\n",
      "\n",
      "**Steps Required Per Ticket:**\n",
      "1. Fetch ticket (get_next_ticket)\n",
      "2. Classify (classify_ticket)\n",
      "3. Research (search_knowledge_base)\n",
      "4. Prioritize (set_priority)\n",
      "5. Route (route_to_team)\n",
      "6. Draft response (draft_response)\n",
      "7. Mark complete (mark_complete)\n",
      "\n",
      "**Tickets Completed: 2 of 5**\n",
      "\n",
      "### TICKET-1 (COMPLETED ‚úì)\n",
      "- Customer: Jane Davis\n",
      "- Issue: Unexpected charge after subscription cancellation\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "- Action: Apologized for billing error, escalated to billing team for refund processing within 5-7 business days\n",
      "\n",
      "### TICKET-2 (COMPLETED ‚úì)\n",
      "- Customer: Alex Jones\n",
      "- Issue: App crashes immediately after update v5.7.18 on MacBook Pro running Windows 11\n",
      "- Category: technical\n",
      "- Priority: high\n",
      "- Team: tech-support\n",
      "- Status: resolved\n",
      "- Action: Provided troubleshooting steps (clear cache/reinstall, check requirements, disable conflicting software, compatibility mode), escalated to tech team for 24hr response\n",
      "- Note: Knowledge base search returned generic troubleshooting steps, not specific to v5.7.18 update issue\n",
      "\n",
      "**Remaining Tickets:** 3 more tickets to process (TICKET-3, TICKET-4, TICKET-5)\n",
      "\n",
      "**Next Action:** Fetch TICKET-3 using get_next_ticket and complete all 7 steps\n",
      "\n",
      "**Key Learnings:**\n",
      "- Complete all 7 steps for each ticket before moving to the next\n",
      "- Knowledge base may not have specific solutions for version-specific issues - provide general troubleshooting and escalate\n",
      "- Available teams include: billing-team, tech-support\n",
      "- Priority levels: high (for critical issues like crashes, billing errors)\n",
      "\n",
      "**Token Usage:** 1,631/200,000 (198,369 remaining)\n",
      "</summary>\n",
      "Turn 10: Input=  1,758 tokens | Output=   60 tokens | Messages= 1 | Cumulative In=  22,769\n",
      "Turn 11: Input=  2,003 tokens | Output=  150 tokens | Messages= 3 | Cumulative In=  24,772\n",
      "Turn 12: Input=  2,480 tokens | Output=  137 tokens | Messages= 5 | Cumulative In=  27,252\n",
      "Turn 13: Input=  2,785 tokens | Output=  285 tokens | Messages= 7 | Cumulative In=  30,037\n",
      "üîÑ Compaction occurred! Messages: 7 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Objective:** Process 5 support tickets from the queue, completing all 7 steps for each ticket in sequence.\n",
      "\n",
      "**Steps Required Per Ticket:**\n",
      "1. Fetch ticket (get_next_ticket)\n",
      "2. Classify (classify_ticket)\n",
      "3. Research (search_knowledge_base)\n",
      "4. Priority (set_priority)\n",
      "5. Route (route_to_team)\n",
      "6. Draft response (draft_response)\n",
      "7. Mark complete (mark_complete)\n",
      "\n",
      "**Tickets Completed: 2 of 5**\n",
      "\n",
      "### TICKET-1 (COMPLETED ‚úì)\n",
      "- Customer: Jane Davis\n",
      "- Issue: Unexpected charge after subscription cancellation\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "- Action: Apologized for billing error, escalated to billing team for refund processing within 5-7 business days\n",
      "\n",
      "### TICKET-2 (COMPLETED ‚úì)\n",
      "- Customer: Alex Jones\n",
      "- Issue: App crashes immediately after update v5.7.18 on MacBook Pro running Windows 11\n",
      "- Category: technical\n",
      "- Priority: high\n",
      "- Team: tech-support\n",
      "- Status: resolved\n",
      "- Action: Provided troubleshooting steps (clear cache/reinstall, check requirements, disable conflicting software, compatibility mode), escalated to tech team for 24hr response\n",
      "\n",
      "### TICKET-3 (IN PROGRESS - 6/7 steps complete)\n",
      "- Customer: Jane Johnson (customer4020@example.com)\n",
      "- Issue: Duplicate charges - charged twice for monthly subscription ($49.99 on Nov 14 and $49.99 on Nov 19)\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: new\n",
      "- Created: 2025-11-20T10:14:04.415927\n",
      "- Steps Completed:\n",
      "  1. ‚úì Fetched ticket\n",
      "  2. ‚úì Classified as billing\n",
      "  3. ‚úì Searched knowledge base (found refund policy: 5-7 business days, billing cycle info)\n",
      "  4. ‚úì Set priority to high\n",
      "  5. ‚úì Routed to billing-team\n",
      "  6. ‚úì Drafted response (apologized for duplicate charge, escalated to billing team, explained 5-7 day refund timeline)\n",
      "  7. ‚è≥ NEXT: Call mark_complete for TICKET-3\n",
      "\n",
      "**Remaining Tickets:** TICKET-4 and TICKET-5 still need to be processed\n",
      "\n",
      "**Next Immediate Action:** Call mark_complete on TICKET-3, then fetch and process TICKET-4 and TICKET-5\n",
      "\n",
      "**Key Learnings:**\n",
      "- Complete all 7 steps for each ticket before moving to the next\n",
      "- Billing issues (charges, refunds) = high priority ‚Üí billing-team\n",
      "- Technical issues (crashes, bugs) = high priority ‚Üí tech-support\n",
      "- Refund processing takes 5-7 business days\n",
      "- Knowledge base provides general policies but may lack specific version/issue details\n",
      "\n",
      "**Token Usage:** 1,650/200,000 (198,350 remaining)\n",
      "</summary>\n",
      "Turn 14: Input=  1,992 tokens | Output=  111 tokens | Messages= 1 | Cumulative In=  32,029\n",
      "Turn 15: Input=  2,434 tokens | Output=  176 tokens | Messages= 3 | Cumulative In=  34,463\n",
      "Turn 16: Input=  3,059 tokens | Output=  418 tokens | Messages= 5 | Cumulative In=  37,522\n",
      "üîÑ Compaction occurred! Messages: 5 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Objective:** Process 5 support tickets from the queue, completing all 7 steps for each ticket in sequence.\n",
      "\n",
      "**Steps Required Per Ticket:**\n",
      "1. Fetch ticket (get_next_ticket)\n",
      "2. Classify (classify_ticket)\n",
      "3. Research (search_knowledge_base)\n",
      "4. Priority (set_priority)\n",
      "5. Route (route_to_team)\n",
      "6. Draft response (draft_response)\n",
      "7. Mark complete (mark_complete)\n",
      "\n",
      "**Tickets Completed: 3 of 5**\n",
      "\n",
      "### TICKET-1 (COMPLETED ‚úì)\n",
      "- Customer: Jane Davis\n",
      "- Issue: Unexpected charge after subscription cancellation\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-2 (COMPLETED ‚úì)\n",
      "- Customer: Alex Jones\n",
      "- Issue: App crashes immediately after update v5.7.18\n",
      "- Category: technical\n",
      "- Priority: high\n",
      "- Team: tech-support\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-3 (COMPLETED ‚úì)\n",
      "- Customer: Jane Johnson (customer4020@example.com)\n",
      "- Issue: Duplicate charges - charged twice for monthly subscription ($49.99 on Nov 14 and $49.99 on Nov 19)\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "- Action: Apologized for duplicate charge, escalated to billing team, explained 5-7 day refund timeline\n",
      "\n",
      "### TICKET-4 (IN PROGRESS - 6/7 steps complete)\n",
      "- Customer: Alex Smith (customer5952@example.com)\n",
      "- Issue: Damaged product delivery (Order #ORD-24420) - box badly damaged, product inside broken, needs replacement\n",
      "- Category: shipping\n",
      "- Priority: high\n",
      "- Team: logistics-team\n",
      "- Status: new\n",
      "- Created: 2025-11-21T04:14:04.415953\n",
      "- Steps Completed:\n",
      "  1. ‚úì Fetched ticket\n",
      "  2. ‚úì Classified as shipping\n",
      "  3. ‚úì Searched knowledge base (no relevant shipping/damage info found - KB only has technical troubleshooting)\n",
      "  4. ‚úì Set priority to high\n",
      "  5. ‚úì Routed to logistics-team\n",
      "  6. ‚úì Drafted response (apologized, escalated to logistics team, promised replacement within 24hrs, mentioned photo documentation helpful but not required)\n",
      "  7. ‚è≥ NEXT: Call mark_complete for TICKET-4\n",
      "\n",
      "**Remaining Tickets:** TICKET-5 still needs to be processed (1 ticket remaining)\n",
      "\n",
      "**Next Immediate Actions:** \n",
      "1. Call mark_complete on TICKET-4\n",
      "2. Fetch TICKET-5 (get_next_ticket)\n",
      "3. Process all 7 steps for TICKET-5\n",
      "\n",
      "**Key Learnings:**\n",
      "- Billing issues (charges, refunds, duplicates) = high priority ‚Üí billing-team\n",
      "- Technical issues (crashes, bugs) = high priority ‚Üí tech-support\n",
      "- Shipping issues (damaged products) = high priority ‚Üí logistics-team\n",
      "- Knowledge base has limited coverage (billing policies, technical troubleshooting, but no shipping/logistics info)\n",
      "- Refund processing: 5-7 business days standard timeline\n",
      "- Response should always acknowledge issue, apologize, explain action taken, provide timeline\n",
      "\n",
      "**Token Usage:** 2,054/200,000 (197,946 remaining)\n",
      "</summary>\n",
      "Turn 17: Input=  2,075 tokens | Output=   91 tokens | Messages= 1 | Cumulative In=  39,597\n",
      "Turn 18: Input=  2,291 tokens | Output=   71 tokens | Messages= 3 | Cumulative In=  41,888\n",
      "Turn 19: Input=  2,532 tokens | Output=  148 tokens | Messages= 5 | Cumulative In=  44,420\n",
      "Turn 20: Input=  2,984 tokens | Output=  456 tokens | Messages= 7 | Cumulative In=  47,404\n",
      "üîÑ Compaction occurred! Messages: 7 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Objective:** Process 5 support tickets from the queue, completing all 7 steps for each ticket in sequence.\n",
      "\n",
      "**Steps Required Per Ticket:**\n",
      "1. Fetch ticket (get_next_ticket)\n",
      "2. Classify (classify_ticket)\n",
      "3. Research (search_knowledge_base)\n",
      "4. Priority (set_priority)\n",
      "5. Route (route_to_team)\n",
      "6. Draft response (draft_response)\n",
      "7. Mark complete (mark_complete)\n",
      "\n",
      "**Tickets Completed: 4 of 5**\n",
      "\n",
      "### TICKET-1 (COMPLETED ‚úì)\n",
      "- Customer: Jane Davis\n",
      "- Issue: Unexpected charge after subscription cancellation\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-2 (COMPLETED ‚úì)\n",
      "- Customer: Alex Jones\n",
      "- Issue: App crashes immediately after update v5.7.18\n",
      "- Category: technical\n",
      "- Priority: high\n",
      "- Team: tech-support\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-3 (COMPLETED ‚úì)\n",
      "- Customer: Jane Johnson (customer4020@example.com)\n",
      "- Issue: Duplicate charges - charged twice for monthly subscription ($49.99 on Nov 14 and $49.99 on Nov 19)\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-4 (COMPLETED ‚úì)\n",
      "- Customer: Alex Smith (customer5952@example.com)\n",
      "- Issue: Damaged product delivery (Order #ORD-24420)\n",
      "- Category: shipping\n",
      "- Priority: high\n",
      "- Team: logistics-team\n",
      "- Status: resolved\n",
      "\n",
      "### TICKET-5 (IN PROGRESS - 6/7 steps complete)\n",
      "- Customer: Chris Smith (customer9136@example.com)\n",
      "- Issue: Change email address from old705@example.com to new333@example.com (no access to old email)\n",
      "- Category: account\n",
      "- Priority: medium\n",
      "- Team: account-services\n",
      "- Status: new\n",
      "- Created: 2025-11-21T11:14:04.415978\n",
      "- Steps Completed:\n",
      "  1. ‚úì Fetched ticket\n",
      "  2. ‚úì Classified as account\n",
      "  3. ‚úì Searched knowledge base (found: \"Email changes require verification of both old and new addresses for security\" - but customer lacks old email access, requires special handling)\n",
      "  4. ‚úì Set priority to medium\n",
      "  5. ‚úì Routed to account-services\n",
      "  6. ‚úì Drafted response (acknowledged special case, escalated to Account Services team, explained identity verification needed, 24hr response timeline, asked customer to prepare account details)\n",
      "  7. ‚è≥ NEXT: Call mark_complete for TICKET-5\n",
      "\n",
      "**Remaining Work:** Only 1 step left - mark TICKET-5 as complete, then all 5 tickets will be done!\n",
      "\n",
      "**Next Immediate Action:** \n",
      "Call mark_complete on TICKET-5 to finish the task\n",
      "\n",
      "**Key Learnings:**\n",
      "- Billing issues (charges, refunds, duplicates) = high priority ‚Üí billing-team\n",
      "- Technical issues (crashes, bugs) = high priority ‚Üí tech-support\n",
      "- Shipping issues (damaged products) = high priority ‚Üí logistics-team\n",
      "- Account issues (email changes, access problems) = medium priority ‚Üí account-services\n",
      "- Knowledge base coverage: billing policies, technical troubleshooting, account security procedures (decent coverage across categories)\n",
      "- Email changes normally require verification of both addresses, but no-access cases need escalation and alternative identity verification\n",
      "- Standard response pattern: acknowledge issue, apologize if appropriate, explain action taken, provide timeline, offer preparation steps\n",
      "\n",
      "**Token Usage:** 2,114/200,000 (197,886 remaining)\n",
      "</summary>\n",
      "Turn 21: Input=  2,145 tokens | Output=   75 tokens | Messages= 1 | Cumulative In=  49,549\n",
      "Turn 22: Input=  2,345 tokens | Output=  290 tokens | Messages= 3 | Cumulative In=  51,894\n",
      "\n",
      "============================================================\n",
      "OPTIMIZED RESULTS (WITH COMPACTION)\n",
      "============================================================\n",
      "Total turns:   22\n",
      "Compactions:   5\n",
      "Input tokens:  51,894\n",
      "Output tokens: 3,856\n",
      "Total tokens:  55,750\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize queue and run with compaction\n",
    "initialize_ticket_queue(num_tickets)\n",
    "\n",
    "total_input_compact = 0\n",
    "total_output_compact = 0\n",
    "turn_count_compact = 0\n",
    "compaction_count = 0\n",
    "prev_msg_count = 0\n",
    "\n",
    "runner = client.beta.messages.tool_runner(\n",
    "    model=MODEL,\n",
    "    max_tokens=4096,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    "    compaction_control={\n",
    "        \"enabled\": True,\n",
    "        \"context_token_threshold\": 3000,\n",
    "    },\n",
    ")\n",
    "\n",
    "for message in runner:\n",
    "    turn_count_compact += 1\n",
    "    total_input_compact += message.usage.input_tokens\n",
    "    total_output_compact += message.usage.output_tokens\n",
    "    messages_list = list(runner._params[\"messages\"])\n",
    "    curr_msg_count = len(messages_list)\n",
    "\n",
    "    if curr_msg_count < prev_msg_count:\n",
    "        compaction_count += 1\n",
    "        print(f\"üîÑ Compaction occurred! Messages: {prev_msg_count} ‚Üí {curr_msg_count}\")\n",
    "        print(\"   Summary message after compaction:\")\n",
    "        print(messages_list[-1]['content'][-1].text)    # type: ignore\n",
    "\n",
    "    prev_msg_count = curr_msg_count\n",
    "    print(\n",
    "            f\"Turn {turn_count_compact:2d}: Input={message.usage.input_tokens:7,} tokens | \"\n",
    "            f\"Output={message.usage.output_tokens:5,} tokens | \"\n",
    "            f\"Messages={len(runner._params['messages']):2d} | \"\n",
    "            f\"Cumulative In={total_input_compact:8,}\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"OPTIMIZED RESULTS (WITH COMPACTION)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Total turns:   {turn_count_compact}\")\n",
    "print(f\"Compactions:   {compaction_count}\")\n",
    "print(f\"Input tokens:  {total_input_compact:,}\")\n",
    "print(f\"Output tokens: {total_output_compact:,}\")\n",
    "print(f\"Total tokens:  {total_input_compact + total_output_compact:,}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24dd5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ **TASK COMPLETED!**\n",
      "\n",
      "All 5 tickets have been successfully processed through all 7 required steps:\n",
      "\n",
      "### Final Summary:\n",
      "\n",
      "**TICKET-1** ‚úì - Jane Davis - Billing (unexpected charge after cancellation) ‚Üí billing-team\n",
      "**TICKET-2** ‚úì - Alex Jones - Technical (app crash v5.7.18) ‚Üí tech-support  \n",
      "**TICKET-3** ‚úì - Jane Johnson - Billing (duplicate charges) ‚Üí billing-team\n",
      "**TICKET-4** ‚úì - Alex Smith - Shipping (damaged product) ‚Üí logistics-team\n",
      "**TICKET-5** ‚úì - Chris Smith - Account (email change without old access) ‚Üí account-services\n",
      "\n",
      "All tickets have been:\n",
      "1. ‚úì Fetched from queue\n",
      "2. ‚úì Classified appropriately\n",
      "3. ‚úì Researched in knowledge base\n",
      "4. ‚úì Prioritized (4 high, 1 medium)\n",
      "5. ‚úì Routed to correct teams\n",
      "6. ‚úì Response drafted\n",
      "7. ‚úì Marked complete\n",
      "\n",
      "**Status:** 5 of 5 tickets completed and ready for team review! üéØ\n"
     ]
    }
   ],
   "source": [
    "print(message.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vb4cesnmb8",
   "metadata": {},
   "source": [
    "### Comparing Results\n",
    "\n",
    "Notice the dramatic difference! With compaction enabled at 5,000 tokens:\n",
    "\n",
    "1. **Context resets after several tickets** - When processing 5-7 tickets generates 5k+ tokens of tool results, the SDK automatically:\n",
    "   - Injects a summary prompt\n",
    "   - Has Claude generate a completion summary wrapped in `<summary></summary>` tags\n",
    "   - Clears the conversation history and discards detailed classifications, KB searches, and responses\n",
    "   - Continues with only the completion summary\n",
    "\n",
    "2. **Input tokens stay bounded** - Instead of accumulating to 100k+ as we process more tickets, input tokens reset after each compaction. When processing Ticket #5, we're NOT carrying the full tool results from Tickets #1-4.\n",
    "\n",
    "3. **Task completes successfully** - The workflow continues smoothly through all tickets without hitting context limits\n",
    "\n",
    "4. **Quality is preserved** - The summaries retain critical information:\n",
    "   - Tickets processed with their IDs\n",
    "   - Categories and priorities assigned\n",
    "   - Teams routed to\n",
    "   - Overall progress status\n",
    "   \n",
    "   All tickets are still properly classified, prioritized, routed, and responded to.\n",
    "\n",
    "5. **Natural workflow** - This mirrors how real support agents work: resolve a ticket, document it briefly in the system, close it, move to the next one. You don't keep every knowledge base article and full response draft open while working on new tickets.\n",
    "\n",
    "Let's visualize the token savings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "z9lvigc94p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOKEN USAGE COMPARISON\n",
      "======================================================================\n",
      "Metric                         Baseline             With Compaction     \n",
      "----------------------------------------------------------------------\n",
      "Input tokens:                              150,881              51,894\n",
      "Output tokens:                               3,902               3,856\n",
      "Total tokens:                              154,783              55,750\n",
      "Compactions:                                   N/A                   5\n",
      "======================================================================\n",
      "\n",
      "üí∞ Token Savings: 99,033 tokens (64.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Compare baseline vs compaction\n",
    "print(\"=\" * 70)\n",
    "print(\"TOKEN USAGE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<30} {'Baseline':<20} {'With Compaction':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Input tokens:':<30} {total_input:>19,} {total_input_compact:>19,}\")\n",
    "print(f\"{'Output tokens:':<30} {total_output:>19,} {total_output_compact:>19,}\")\n",
    "print(\n",
    "    f\"{'Total tokens:':<30} {total_input + total_output:>19,} {total_input_compact + total_output_compact:>19,}\"\n",
    ")\n",
    "print(f\"{'Compactions:':<30} {'N/A':>19} {compaction_count:>19}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate savings\n",
    "token_savings = (total_input + total_output) - (total_input_compact + total_output_compact)\n",
    "savings_percent = (\n",
    "    (token_savings / (total_input + total_output)) * 100 if (total_input + total_output) > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"\\nüí∞ Token Savings: {token_savings:,} tokens ({savings_percent:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lzvf1mw7o6",
   "metadata": {},
   "source": [
    "## How Compaction Works Under the Hood\n",
    "\n",
    "When the `tool_runner` detects that token usage has exceeded the threshold, it automatically:\n",
    "\n",
    "1. **Pauses the workflow** before making the next API call\n",
    "2. **Injects a summary request** as a user message asking Claude to summarize progress\n",
    "3. **Generates a summary** - Claude produces a summary wrapped in `<summary></summary>` tags containing:\n",
    "   - **Completed tickets**: Brief records of tickets resolved (IDs, categories, priorities, outcomes)\n",
    "   - **Progress status**: How many tickets processed, how many remain\n",
    "   - **Key patterns**: Any notable trends across tickets\n",
    "   - **Next steps**: What to do next (continue processing remaining tickets)\n",
    "4. **Clears history** - The entire conversation history (including all tool results) is replaced with just the summary\n",
    "5. **Resumes processing** - Claude continues working with the compressed context, processing the next batch of tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v64ljd0a79",
   "metadata": {},
   "source": [
    "## Customizing Compaction Configuration\n",
    "\n",
    "You can customize how compaction works to fit your specific use case. Here are the key configuration options:\n",
    "\n",
    "### Adjusting the Threshold\n",
    "\n",
    "The `context_token_threshold` determines when compaction triggers:\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"context_token_threshold\": 5000,  # Compact after processing 5-7 tickets\n",
    "}\n",
    "```\n",
    "\n",
    "**Guidelines:**\n",
    "- **Very low thresholds (5k-20k)**: \n",
    "  - Use for iterative task processing with clear boundaries\n",
    "  - Our customer service workflow uses 5k to compact after processing several tickets\n",
    "  - More frequent compaction, minimal context accumulation\n",
    "  - Best for sequential entity processing\n",
    "  \n",
    "- **Medium thresholds (50k-100k)**: \n",
    "  - Multi-phase workflows with fewer, larger natural checkpoints\n",
    "  - Balance between context retention and management\n",
    "  - Suitable for workflows with expensive tool calls\n",
    "  \n",
    "- **High thresholds (100k-150k)**: \n",
    "  - Tasks requiring substantial historical context\n",
    "  - Less frequent compaction preserves more raw details\n",
    "  - Higher per-call costs but fewer compactions\n",
    "  \n",
    "- **Default (150k)**: Good balance for general long-running tasks\n",
    "\n",
    "**For ticket processing**: The 5k threshold works well because each ticket's workflow generates substantial tool results, but tickets are independent. After resolving Ticket A, you don't need its detailed KB searches when processing Ticket B.\n",
    "\n",
    "### Using a Different Model for Summarization\n",
    "\n",
    "You can use a faster/cheaper model for generating summaries:\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"model\": \"claude-haiku-4-5\",  # Use Haiku for cost-effective summaries\n",
    "}\n",
    "```\n",
    "\n",
    "This is useful when you want to optimize costs - Haiku can generate good summaries much cheaper than Sonnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w4oyvorzkn",
   "metadata": {},
   "source": [
    "### Custom Summary Prompts\n",
    "\n",
    "You can provide a custom prompt to guide how summaries are generated. This is especially useful for customer service workflows where you need to preserve specific types of information.\n",
    "\n",
    "For our workflow, we want to ensure each compaction retains:\n",
    "- **Ticket summaries** for all completed tickets\n",
    "- **Categories and priorities** assigned\n",
    "- **Teams routed to**\n",
    "- **Progress status** (tickets completed, tickets remaining)\n",
    "- **Next steps** in the workflow\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"summary_prompt\": \"\"\"You are processing customer support tickets from a queue.\n",
    "\n",
    "Create a focused summary that preserves:\n",
    "\n",
    "1. **COMPLETED TICKETS**: For each ticket you've fully processed:\n",
    "   - Ticket ID and customer name\n",
    "   - Issue category and priority assigned\n",
    "   - Team routed to\n",
    "   - Brief outcome\n",
    "\n",
    "2. **PROGRESS STATUS**: \n",
    "   - How many tickets you've completed\n",
    "   - Approximately how many remain in the queue\n",
    "\n",
    "3. **NEXT STEPS**: Continue processing the next ticket\n",
    "\n",
    "Format with clear sections and wrap in <summary></summary> tags.\"\"\"\n",
    "}\n",
    "```\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vdfwgq0ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Custom summaries completed in 21 turns\n",
      "   Each summary maintains structured records while discarding verbose tool results.\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize queue with custom summary prompt\n",
    "initialize_ticket_queue(num_tickets)\n",
    "\n",
    "custom_summary_prompt = \"\"\"You are processing customer support tickets from a queue.\n",
    "\n",
    "Create a focused summary that preserves:\n",
    "\n",
    "1. **COMPLETED TICKETS**: For each ticket you've fully processed:\n",
    "   - Ticket ID and customer name\n",
    "   - Issue category and priority assigned\n",
    "   - Team routed to\n",
    "   - Brief outcome\n",
    "\n",
    "2. **PROGRESS STATUS**:\n",
    "   - How many tickets you've completed\n",
    "   - Approximately how many remain in the queue\n",
    "\n",
    "3. **NEXT STEPS**: Continue processing the next ticket\n",
    "\n",
    "Format with clear sections. Wrap in <summary></summary> tags.\"\"\"\n",
    "\n",
    "runner = client.beta.messages.tool_runner(\n",
    "    model=MODEL,\n",
    "    max_tokens=4096,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    "    compaction_control={\n",
    "        \"enabled\": True,\n",
    "        \"context_token_threshold\": 5000,\n",
    "        \"summary_prompt\": custom_summary_prompt,\n",
    "    },\n",
    ")\n",
    "\n",
    "turn_count_custom = 0\n",
    "for message in runner:\n",
    "    turn_count_custom += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Custom summaries completed in {turn_count_custom} turns\")\n",
    "print(\"   Each summary maintains structured records while discarding verbose tool results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3602dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect! It appears TICKET-5 has already been completed. \n",
      "\n",
      "## ‚úÖ ALL TICKETS PROCESSED - SESSION COMPLETE\n",
      "\n",
      "### FINAL SUMMARY\n",
      "\n",
      "**5 of 5 tickets successfully processed:**\n",
      "\n",
      "1. **TICKET-1** - Morgan Brown: App crashes (iPhone) ‚Üí Tech Support [HIGH]\n",
      "2. **TICKET-2** - Chris Smith: Invalid tracking number ‚Üí Logistics Team [MEDIUM]\n",
      "3. **TICKET-3** - John Brown: Plan comparison inquiry ‚Üí Product Success [LOW]\n",
      "4. **TICKET-4** - Alex Johnson: App crashes (Android) ‚Üí Tech Support [HIGH]\n",
      "5. **TICKET-5** - Morgan Davis: Upload permission errors ‚Üí Tech Support [HIGH/URGENT]\n",
      "\n",
      "### PROCESSING STATISTICS\n",
      "- **Total Tickets:** 5\n",
      "- **Completion Rate:** 100%\n",
      "- **Categories Handled:** Technical (3), Shipping (1), Product (1)\n",
      "- **Priority Distribution:** \n",
      "  - High/Urgent: 3 tickets\n",
      "  - Medium: 1 ticket\n",
      "  - Low: 1 ticket\n",
      "\n",
      "All tickets have been classified, prioritized, routed to appropriate teams, and provided with drafted responses. The support teams can now review and send the responses to customers.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7emc6ezm9",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "When using automatic context compaction, follow these guidelines:\n",
    "\n",
    "### 1. Choose the Right Threshold\n",
    "\n",
    "- **Start with the default (150k)** for most workflows\n",
    "- **Lower thresholds (5k-20k)** for:\n",
    "  - **Iterative processing** like our ticket workflow (compact after processing several items)\n",
    "  - **Multi-phase workflows** with natural checkpoints\n",
    "  - Very long-running tasks that need many iterations\n",
    "  - Cost-sensitive applications\n",
    "  - Tasks where older context becomes less relevant\n",
    "- **Higher thresholds (100k-150k)** for:\n",
    "  - Tasks requiring detailed historical context across all phases\n",
    "  - Complex reasoning that builds on previous steps\n",
    "  - Workflows with expensive tool calls where you want to minimize repetition\n",
    "\n",
    "**For ticket processing**: A threshold of 5k-10k works well because each ticket workflow is self-contained. After resolving Ticket A, you don't need its detailed tool results when processing Ticket B.\n",
    "\n",
    "### 2. Craft Effective Summary Prompts\n",
    "\n",
    "Good summary prompts should specify:\n",
    "- **What to preserve**: Critical information, IDs, categories, outcomes, progress\n",
    "- **Format**: Structured output helps maintain consistency\n",
    "- **Context**: Remind Claude of the task and current phase\n",
    "- **Next steps**: What remains to be done\n",
    "\n",
    "Example for ticket processing:\n",
    "```python\n",
    "summary_prompt = \"\"\"You are processing customer support tickets.\n",
    "\n",
    "Include in your summary:\n",
    "- COMPLETED: Brief record of each ticket (ID, category, priority, team, outcome)\n",
    "- PROGRESS: Tickets completed vs remaining\n",
    "- NEXT: Continue processing remaining tickets\n",
    "\n",
    "Wrap in <summary></summary> tags.\"\"\"\n",
    "```\n",
    "\n",
    "### 3. Use Appropriate Models\n",
    "\n",
    "- **Main task**: Use the model best suited for the task (Sonnet, Haiku)\n",
    "- **Summarization**: Consider using Haiku for cost savings if summaries don't require complex reasoning\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"model\": \"claude-haiku-4-5\",  # Cheaper summaries\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. Monitor Compaction Behavior\n",
    "\n",
    "Track when compaction occurs to optimize your threshold:\n",
    "\n",
    "```python\n",
    "messages_list = list(runner._params[\"messages\"])\n",
    "curr_msg_count = len(messages_list)\n",
    "\n",
    "if curr_msg_count < prev_msg_count:\n",
    "    print(f\"Compaction at turn {turn_count}\")\n",
    "    \n",
    "prev_msg_count = curr_msg_count\n",
    "```\n",
    "\n",
    "In our ticket workflow, you should see compaction trigger after processing several tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dwo1dayp",
   "metadata": {},
   "source": [
    "## Limitations and Considerations\n",
    "\n",
    "While automatic context compaction is powerful, there are important limitations to understand:\n",
    "\n",
    "### ‚ö†Ô∏è Server-Side Sampling Loops\n",
    "\n",
    "**Current Limitation**: Compaction does not work optimally with server-side sampling loops, such as server-side web search tools.\n",
    "\n",
    "**Why**: Cache tokens accumulate across sampling loops, which can trigger compaction prematurely based on cached content rather than actual conversation history.\n",
    "\n",
    "**Workaround**: This feature works best with:\n",
    "- ‚úÖ Client-side tools (like the customer service API in this cookbook)\n",
    "- ‚úÖ Standard agentic workflows with regular tool use\n",
    "- ‚úÖ File operations, database queries, API calls\n",
    "- ‚ùå Server-side Extended Thinking\n",
    "- ‚ùå Server-side web search tools\n",
    "\n",
    "### Information Loss\n",
    "\n",
    "**Trade-off**: Summaries inherently lose some information. While Claude is good at identifying key points, some details will be compressed or omitted.\n",
    "\n",
    "**In ticket processing**: \n",
    "- ‚úÖ **Retained**: Ticket IDs, categories, priorities, teams, outcomes, progress status\n",
    "- ‚ùå **Lost**: Full knowledge base article text, complete drafted response text, detailed classification reasoning\n",
    "\n",
    "This is usually acceptable‚Äîyou don't need every KB article and full response text in perpetuity, just the completion records.\n",
    "\n",
    "**Mitigation**:\n",
    "- Use custom summary prompts to preserve critical information\n",
    "- Set higher thresholds for tasks requiring extensive historical context\n",
    "- Structure your tasks to be modular (each phase builds on summaries, not raw details)\n",
    "\n",
    "### When NOT to Use Compaction\n",
    "\n",
    "Avoid compaction for:\n",
    "\n",
    "1. **Short tasks**: If your task completes within 50k-100k tokens, compaction adds unnecessary overhead\n",
    "2. **Tasks requiring full audit trails**: Some tasks need access to ALL previous details\n",
    "3. **Server-side sampling workflows**: As mentioned above, wait for this limitation to be addressed\n",
    "4. **Highly iterative refinement**: Tasks where each step critically depends on exact details from all previous steps\n",
    "\n",
    "### When TO Use Compaction\n",
    "\n",
    "Compaction is ideal for:\n",
    "\n",
    "1. **Sequential processing**: Like our ticket workflow‚Äîprocess multiple items one after another\n",
    "2. **Multi-phase workflows**: Where each phase can summarize progress before moving on\n",
    "3. **Iterative data processing**: Processing large datasets in chunks or entities one at a time\n",
    "4. **Extended analysis sessions**: Analyzing data across many entities\n",
    "5. **Batch operations**: Processing hundreds of items where each is independent\n",
    "\n",
    "**Ticket processing is a perfect use case** because:\n",
    "- Each ticket workflow is largely independent\n",
    "- You need completion summaries, not full tool results\n",
    "- Natural compaction points exist (after completing several tickets)\n",
    "- The workflow is iterative and sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4pz1jmdidi",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Automatic context compaction is a powerful feature that enables long-running agentic workflows to exceed typical context limits. In this cookbook, we've explored compaction through a customer service ticket processing workflow.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **The Problem**: Without compaction, iterative workflows face severe challenges:\n",
    "   - **Context accumulation**: Processing Ticket #10 means carrying tool results from Tickets #1-9\n",
    "   - **Exponential token growth**: Each new ticket adds to an ever-growing context\n",
    "   - **High costs**: Thousands of unnecessary tokens sent with each API call\n",
    "   - **Context limits**: Risk of hitting 200k token limit before completing all tickets\n",
    "\n",
    "2. **The Solution**: The `compaction_control` parameter automates context management:\n",
    "   ```python\n",
    "   compaction_control={\n",
    "       \"enabled\": True,\n",
    "       \"context_token_threshold\": 5000,  # Compact after processing several tickets\n",
    "       \"model\": \"claude-haiku-4-5\",      # Optional, defaults to main model\n",
    "       \"summary_prompt\": \"...\"            # Optional, customize for your use case\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **How It Works**: When tokens exceed the threshold, the SDK:\n",
    "   - Pauses the workflow\n",
    "   - Generates a summary of progress and completed tickets\n",
    "   - Clears the conversation history (discarding detailed tool results)\n",
    "   - Continues seamlessly with compressed context (retaining completion summaries)\n",
    "\n",
    "4. **Real Impact**: In our ticket processing example, compaction enabled:\n",
    "   - Processing all 10 tickets with 70+ tool calls\n",
    "   - Managing classifications, KB searches, and drafted responses for each ticket\n",
    "   - **Significant token savings** (30-60%+ reduction in total tokens)\n",
    "   - **Successful completion** without hitting context limits\n",
    "   - **Quality preserved**: All tickets properly classified, prioritized, routed, and resolved\n",
    "\n",
    "5. **Natural Workflow**: Compaction mirrors how real support agents work:\n",
    "   - Process Ticket A thoroughly ‚Üí Document completion briefly\n",
    "   - Close that ticket and clear your workspace\n",
    "   - Move to Ticket B with a clean slate\n",
    "   - At the end, all tickets are documented in the system\n",
    "   \n",
    "   You don't keep every knowledge base article and full response draft open while working on new tickets.\n",
    "\n",
    "### When to Use Compaction\n",
    "\n",
    "- ‚úÖ Sequential processing (customer service, data processing)\n",
    "- ‚úÖ Iterative workflows (process hundreds of items)\n",
    "- ‚úÖ Multi-phase workflows with natural checkpoints\n",
    "- ‚úÖ Tasks processing large volumes of tool results\n",
    "- ‚úÖ Cost-sensitive production applications\n",
    "- ‚ùå Tasks requiring full, uncompressed conversation history\n",
    "- ‚ùå Server-side sampling loop workflows (current limitation)\n",
    "\n",
    "### Key Configuration Guidelines\n",
    "\n",
    "- **5k-20k threshold**: For iterative processing with natural per-item compaction points\n",
    "- **50k-100k threshold**: For multi-phase workflows with fewer, larger compaction points\n",
    "- **150k threshold (default)**: For general long-running tasks\n",
    "- **Custom summary prompts**: Essential for preserving workflow-specific information\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Try implementing compaction in your own workflows:\n",
    "1. Identify natural compaction points (after processing each item, completing each phase, etc.)\n",
    "2. Start with an aggressive threshold (5k-10k) if you have clear per-item boundaries\n",
    "3. Use custom summary prompts to preserve critical information\n",
    "4. Monitor when compaction triggers and verify quality is maintained\n",
    "5. Adjust threshold based on your specific needs\n",
    "\n",
    "For more on effective context management, see [Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anthropic-cookbook (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
