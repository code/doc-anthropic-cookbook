{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb718d24",
   "metadata": {},
   "source": [
    "# Automatic Context Compaction\n",
    "\n",
    "Long-running agentic tasks can often exceed context limits. Tool heavy workflows or long conversations quickly consume the token context window. In [Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), we discussed how managing context can help avoid performance degradation and context rot.\n",
    "\n",
    "The Claude Agent Python SDK can help manage this context by automatically compressing conversation history when token usage exceeds a configurable threshold, allowing tasks to continue beyond the typical 200k token context limit.\n",
    "\n",
    "In this cookbook, we'll demonstrate context compaction through an **agentic customer service workflow**. Imagine you've built an AI customer service agent tasked with processing a queue of support tickets. For each ticket, you must classify the issue, search the knowledge base, set priority, route to the appropriate team, draft a response, and mark it complete. As you process ticket after ticket, the conversation history fills with classifications, knowledge base searches, and drafted responses‚Äîquickly consuming thousands of tokens.\n",
    "\n",
    "## What is Context Compaction?\n",
    "\n",
    "When building agentic workflows with tool use, conversations can grow very large as the agent iterates on complex tasks. The `compaction_control` parameter provides automatic context management by:\n",
    "\n",
    "1. Monitoring token usage per turn in the conversation\n",
    "2. When a threshold is exceeded, injecting a summary prompt as a user turn\n",
    "3. Having the model generate a summary wrapped in `<summary></summary>` tags. These tags aren't parsed, but are there to help guide the model.\n",
    "4. Clearing the conversation history and resuming with only the summary\n",
    "5. Continuing the task with the compressed context\n",
    "\n",
    "## By the end of this cookbook, you'll be able to:\n",
    " \n",
    " - Understand how to effectively manage context limits in iterative workflows\n",
    " - Write agents that leverage automatic context compaction\n",
    " - Design workflows that maintain focus across multiple iterations\n",
    "\n",
    "##  Prerequisites\n",
    "\n",
    "Before following this guide, ensure you have:\n",
    "\n",
    "**Required Knowledge**\n",
    "\n",
    "- Basic understanding of agentic patterns and tool calling\n",
    "\n",
    "**Required Tools**\n",
    "\n",
    "- Python 3.11 or higher\n",
    "- Anthropic API key\n",
    "- Anthropic SDK >= 0.74.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e3b52",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pedram/code/claude-cookbooks-private/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba96da5",
   "metadata": {},
   "source": [
    "Note: Ensure your .env file contains:\n",
    "\n",
    "`ANTHROPIC_API_KEY=your_key_here`\n",
    "\n",
    "Load your environment variables and configure the client. We also load a helper utility to visualize Claude message responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f6d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils.visualize import visualize\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"claude-sonnet-4-5\"\n",
    "viz = visualize(auto_show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cf8e3",
   "metadata": {},
   "source": [
    "## Setting the Stage\n",
    "\n",
    "In [utils/customer_service_tools.py](utils/customer_service_tools.py), we've defined several functions for processing customer support tickets:\n",
    "\n",
    "- `get_next_ticket()` - Retrieves the next unprocessed ticket from the queue\n",
    "- `classify_ticket(ticket_id, category)` - Categorizes issues as billing, technical, account, product, or shipping\n",
    "- `search_knowledge_base(query)` - Finds relevant help articles and solutions\n",
    "- `set_priority(ticket_id, priority)` - Assigns priority levels (low, medium, high, urgent)\n",
    "- `route_to_team(ticket_id, team)` - Routes tickets to the appropriate support team\n",
    "- `draft_response(ticket_id, response_text)` - Creates customer-facing responses\n",
    "- `mark_complete(ticket_id)` - Finalizes processed tickets\n",
    "\n",
    "For a customer service agent, these tools enable processing tickets systematically. Each ticket requires classification, research, prioritization, routing, and response drafting. When processing 20-30 tickets in sequence, the conversation history fills with tool results from every classification, every knowledge base search, and every drafted response, causing linear token growth.\n",
    "\n",
    "The `beta_tool` decorator is used on the tools to make them accessible to the Claude agent. The decorator extracts the function arguments and docstring and provides these to Claude as tool metadata.\n",
    "\n",
    "```python\n",
    "import anthropic\n",
    "from anthropic import beta_tool\n",
    "\n",
    "@beta_tool\n",
    "def get_next_ticket() -> dict:\n",
    "    \"\"\"Retrieve the next unprocessed support ticket from the queue.\"\"\"\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d2a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from utils.customer_service_tools import (\n",
    "    classify_ticket,\n",
    "    draft_response,\n",
    "    get_next_ticket,\n",
    "    initialize_ticket_queue,\n",
    "    mark_complete,\n",
    "    route_to_team,\n",
    "    search_knowledge_base,\n",
    "    set_priority,\n",
    ")\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "tools = [\n",
    "    get_next_ticket,\n",
    "    classify_ticket,\n",
    "    search_knowledge_base,\n",
    "    set_priority,\n",
    "    route_to_team,\n",
    "    draft_response,\n",
    "    mark_complete,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fecfb8",
   "metadata": {},
   "source": [
    "## Baseline: Running Without Compaction\n",
    "\n",
    "Let's start with a realistic customer service scenario: Processing a queue of support tickets. \n",
    "\n",
    "The workflow looks like this:\n",
    "\n",
    "**For Each Ticket:**\n",
    "1. Fetch the ticket using `get_next_ticket()`\n",
    "2. Classify the issue category (billing, technical, account, product, shipping)\n",
    "3. Search the knowledge base for relevant information\n",
    "4. Set appropriate priority (low, medium, high, urgent)\n",
    "5. Route to the correct team\n",
    "6. Draft a customer response\n",
    "7. Mark the ticket complete\n",
    "8. Move to the next ticket\n",
    "\n",
    "**The Challenge**: With 5 tickets in the queue, and each requiring 7 tool calls, Claude will make 35 or more tool calls. The results from each step including classification knowledge base search, and drafted responses accumulate in the conversation history. Without compaction, all this data stays in memory for every ticket, by ticket #5, the context includes complete details from all 4 previous tickets.\n",
    "\n",
    "Let's run this workflow **without compaction** first and observe what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uef86nvtl4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn  1: Input=  1,537 tokens | Output=   57 tokens | Messages= 1 | Cumulative In=   1,537\n",
      "Turn  2: Input=  1,759 tokens | Output=  153 tokens | Messages= 3 | Cumulative In=   3,296\n",
      "Turn  3: Input=  2,221 tokens | Output=  137 tokens | Messages= 5 | Cumulative In=   5,517\n",
      "Turn  4: Input=  2,526 tokens | Output=  245 tokens | Messages= 7 | Cumulative In=   8,043\n",
      "Turn  5: Input=  2,820 tokens | Output=   58 tokens | Messages= 9 | Cumulative In=  10,863\n",
      "Turn  6: Input=  3,003 tokens | Output=   57 tokens | Messages=11 | Cumulative In=  13,866\n",
      "Turn  7: Input=  3,234 tokens | Output=  141 tokens | Messages=13 | Cumulative In=  17,100\n",
      "Turn  8: Input=  3,703 tokens | Output=  137 tokens | Messages=15 | Cumulative In=  20,803\n",
      "Turn  9: Input=  4,008 tokens | Output=  277 tokens | Messages=17 | Cumulative In=  24,811\n",
      "Turn 10: Input=  4,334 tokens | Output=   58 tokens | Messages=19 | Cumulative In=  29,145\n",
      "Turn 11: Input=  4,516 tokens | Output=   56 tokens | Messages=21 | Cumulative In=  33,661\n",
      "Turn 12: Input=  4,750 tokens | Output=  144 tokens | Messages=23 | Cumulative In=  38,411\n",
      "Turn 13: Input=  5,345 tokens | Output=  137 tokens | Messages=25 | Cumulative In=  43,756\n",
      "Turn 14: Input=  5,650 tokens | Output=  344 tokens | Messages=27 | Cumulative In=  49,406\n",
      "Turn 15: Input=  6,044 tokens | Output=   58 tokens | Messages=29 | Cumulative In=  55,450\n",
      "Turn 16: Input=  6,226 tokens | Output=   56 tokens | Messages=31 | Cumulative In=  61,676\n",
      "Turn 17: Input=  6,450 tokens | Output=  141 tokens | Messages=33 | Cumulative In=  68,126\n",
      "Turn 18: Input=  6,919 tokens | Output=  137 tokens | Messages=35 | Cumulative In=  75,045\n",
      "Turn 19: Input=  7,224 tokens | Output=  323 tokens | Messages=37 | Cumulative In=  82,269\n",
      "Turn 20: Input=  7,597 tokens | Output=   58 tokens | Messages=39 | Cumulative In=  89,866\n",
      "Turn 21: Input=  7,781 tokens | Output=   62 tokens | Messages=41 | Cumulative In=  97,647\n",
      "Turn 22: Input=  8,011 tokens | Output=  145 tokens | Messages=43 | Cumulative In= 105,658\n",
      "Turn 23: Input=  8,484 tokens | Output=  137 tokens | Messages=45 | Cumulative In= 114,142\n",
      "Turn 24: Input=  8,789 tokens | Output=  323 tokens | Messages=47 | Cumulative In= 122,931\n",
      "Turn 25: Input=  9,162 tokens | Output=   58 tokens | Messages=49 | Cumulative In= 132,093\n",
      "Turn 26: Input=  9,346 tokens | Output=   63 tokens | Messages=51 | Cumulative In= 141,439\n",
      "Turn 27: Input=  9,442 tokens | Output=  340 tokens | Messages=53 | Cumulative In= 150,881\n",
      "\n",
      "============================================================\n",
      "BASELINE RESULTS (NO COMPACTION)\n",
      "============================================================\n",
      "Total turns:   27\n",
      "Input tokens:  150,881\n",
      "Output tokens: 3,902\n",
      "Total tokens:  154,783\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from anthropic.types.beta import BetaMessageParam\n",
    "\n",
    "num_tickets = 5\n",
    "initialize_ticket_queue(num_tickets)\n",
    "\n",
    "messages: list[BetaMessageParam] = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are an AI customer service agent. Your task is to process support tickets from a queue.\n",
    "\n",
    "For EACH ticket, you must complete ALL these steps:\n",
    "\n",
    "1. **Fetch ticket**: Call get_next_ticket() to retrieve the next unprocessed ticket\n",
    "2. **Classify**: Call classify_ticket() to categorize the issue (billing/technical/account/product/shipping)\n",
    "3. **Research**: Call search_knowledge_base() to find relevant information for this ticket type\n",
    "4. **Prioritize**: Call set_priority() to assign priority (low/medium/high/urgent) based on severity\n",
    "5. **Route**: Call route_to_team() to assign to the appropriate team\n",
    "6. **Draft**: Call draft_response() to create a helpful customer response using KB information\n",
    "7. **Complete**: Call mark_complete() to finalize this ticket\n",
    "8. **Continue**: Immediately fetch the next ticket and repeat\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Process tickets ONE AT A TIME in sequence\n",
    "- Complete ALL 7 steps for each ticket before moving to the next\n",
    "- Keep fetching and processing tickets until you get an error that the queue is empty\n",
    "- There are {num_tickets} tickets total - process all of them\n",
    "- Be thorough but efficient\n",
    "\n",
    "Begin by fetching the first ticket.\"\"\",\n",
    "    }\n",
    "]\n",
    "\n",
    "total_input = 0\n",
    "total_output = 0\n",
    "turn_count = 0\n",
    "\n",
    "runner = client.beta.messages.tool_runner(\n",
    "    model=MODEL,\n",
    "    max_tokens=4096,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "for message in runner:\n",
    "    turn_count += 1\n",
    "    total_input += message.usage.input_tokens\n",
    "    total_output += message.usage.output_tokens\n",
    "    print(\n",
    "            f\"Turn {turn_count:2d}: Input={message.usage.input_tokens:7,} tokens | \"\n",
    "            f\"Output={message.usage.output_tokens:5,} tokens | \"\n",
    "            f\"Messages={len(messages_list):2d} | \"\n",
    "            f\"Cumulative In={total_input:8,}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"BASELINE RESULTS (NO COMPACTION)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Total turns:   {turn_count}\")\n",
    "print(f\"Input tokens:  {total_input:,}\")\n",
    "print(f\"Output tokens: {total_output:,}\")\n",
    "print(f\"Total tokens:  {total_input + total_output:,}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd25c6f",
   "metadata": {},
   "source": [
    "Now that we have our baseline, we have a better picture of how context grows without compaction. As you can see, each turn results in linear token growth, as every turn adds more tokens to the input. \n",
    "\n",
    "This leads to high token consumption and potential context limits being reached quickly. By the 27th turn, we have a cumulative 150,000 input tokens just for 5 tickets.\n",
    "\n",
    "Let's review Claude's final response after processing all 5 tickets without compaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b51b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect! It appears TICKET-5 has already been completed. \n",
      "\n",
      "## ‚úÖ ALL TICKETS PROCESSED - SESSION COMPLETE\n",
      "\n",
      "### FINAL SUMMARY\n",
      "\n",
      "**5 of 5 tickets successfully processed:**\n",
      "\n",
      "1. **TICKET-1** - Morgan Brown: App crashes (iPhone) ‚Üí Tech Support [HIGH]\n",
      "2. **TICKET-2** - Chris Smith: Invalid tracking number ‚Üí Logistics Team [MEDIUM]\n",
      "3. **TICKET-3** - John Brown: Plan comparison inquiry ‚Üí Product Success [LOW]\n",
      "4. **TICKET-4** - Alex Johnson: App crashes (Android) ‚Üí Tech Support [HIGH]\n",
      "5. **TICKET-5** - Morgan Davis: Upload permission errors ‚Üí Tech Support [HIGH/URGENT]\n",
      "\n",
      "### PROCESSING STATISTICS\n",
      "- **Total Tickets:** 5\n",
      "- **Completion Rate:** 100%\n",
      "- **Categories Handled:** Technical (3), Shipping (1), Product (1)\n",
      "- **Priority Distribution:** \n",
      "  - High/Urgent: 3 tickets\n",
      "  - Medium: 1 ticket\n",
      "  - Low: 1 ticket\n",
      "\n",
      "All tickets have been classified, prioritized, routed to appropriate teams, and provided with drafted responses. The support teams can now review and send the responses to customers.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "klok33ohsvn",
   "metadata": {},
   "source": [
    "### Understanding the Problem\n",
    "\n",
    "In the baseline workflow above, Claude had to:\n",
    "- Process **5 support tickets** sequentially\n",
    "- Complete **7 steps per ticket** (fetch, classify, research, prioritize, route, draft, complete)\n",
    "- Make **35 tool calls** with results accumulating in conversation history\n",
    "- Store **every classification, every knowledge base search, every drafted response** in memory\n",
    "\n",
    "**Why This Happens**:\n",
    "1. **Linear token growth** - With each tool use, the entire conversation history (including all previous tool results) is sent to Claude\n",
    "2. **Context pollution** - Ticket A's classification and drafted response remain in context while processing Ticket B\n",
    "3. **Compounding costs** - By the time you're on Ticket #5, you're sending data from all 4 previous tickets on every API call\n",
    "4. **Slower responses** - Processing massive contexts takes longer\n",
    "5. **Risk of hitting limits** - Eventually you hit the 200k token context window\n",
    "\n",
    "\n",
    "**What We Actually Need**: After completing Ticket A, we only need a **brief summary** (ticket resolved, category, priority) - not the full classification result, knowledge base search, and complete drafted response. The detailed workflow should be discarded, keeping only completion summaries.\n",
    "\n",
    "Let's see how automatic context compaction solves this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "byut5h7hi3",
   "metadata": {},
   "source": [
    "## Enabling Automatic Context Compaction\n",
    "\n",
    "Let's run the exact same customer service workflow, but with automatic context compaction enabled. We simply add the `compaction_control` parameter to our tool runner.\n",
    "\n",
    "The `compaction_control` parameter has one required field and several optional ones:\n",
    "\n",
    "- **`enabled`** (required): Boolean to turn compaction on/off\n",
    "- **`context_token_threshold`** (optional): Token count that triggers compaction (default: 100,000)\n",
    "- **`model`** (optional): Model to use for summarization (defaults to the main model)\n",
    "- **`summary_prompt`** (optional): Custom prompt for generating summaries\n",
    "\n",
    "For this customer service workflow, we'll use a **5,000 token threshold**. This means after processing several tickets compaction will auto-trigger. This allows Claude to:\n",
    "1. **Keep completion summaries** (tickets resolved, categories, outcomes)\n",
    "2. **Discard detailed tool results** (full KB articles, complete classifications, drafted response text)\n",
    "3. **Start fresh** when processing the next batch of tickets\n",
    "\n",
    "This mimics how a real support agent works: resolve the ticket, document it briefly, move to the next case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "x6lnx8d20fr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn  1: Input=  1,537 tokens | Output=   57 tokens | Messages= 1 | Cumulative In=   1,537\n",
      "Turn  2: Input=  1,760 tokens | Output=  101 tokens | Messages= 3 | Cumulative In=   3,297\n",
      "Turn  3: Input=  1,904 tokens | Output=   87 tokens | Messages= 5 | Cumulative In=   5,201\n",
      "Turn  4: Input=  2,212 tokens | Output=   84 tokens | Messages= 7 | Cumulative In=   7,413\n",
      "Turn  5: Input=  2,360 tokens | Output=   89 tokens | Messages= 9 | Cumulative In=   9,773\n",
      "Turn  6: Input=  2,512 tokens | Output=  284 tokens | Messages=11 | Cumulative In=  12,285\n",
      "Turn  7: Input=  2,845 tokens | Output=   67 tokens | Messages=13 | Cumulative In=  15,130\n",
      "Turn  8: Input=  3,037 tokens | Output=   56 tokens | Messages=15 | Cumulative In=  18,167\n",
      "Turn  9: Input=  3,259 tokens | Output=   97 tokens | Messages=17 | Cumulative In=  21,426\n",
      "Turn 10: Input=  3,399 tokens | Output=   88 tokens | Messages=19 | Cumulative In=  24,825\n",
      "Turn 11: Input=  3,731 tokens | Output=   84 tokens | Messages=21 | Cumulative In=  28,556\n",
      "Turn 12: Input=  3,879 tokens | Output=   89 tokens | Messages=23 | Cumulative In=  32,435\n",
      "Turn 13: Input=  4,031 tokens | Output=  331 tokens | Messages=25 | Cumulative In=  36,466\n",
      "Turn 14: Input=  4,412 tokens | Output=   67 tokens | Messages=27 | Cumulative In=  40,878\n",
      "Turn 15: Input=  4,603 tokens | Output=   56 tokens | Messages=29 | Cumulative In=  45,481\n",
      "Turn 16: Input=  4,819 tokens | Output=   97 tokens | Messages=31 | Cumulative In=  50,300\n",
      "Turn 17: Input=  4,959 tokens | Output=   87 tokens | Messages=33 | Cumulative In=  55,259\n",
      "\n",
      "============================================================\n",
      "üîÑ Compaction occurred! Messages: 33 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Progress Summary\n",
      "\n",
      "**Overall Task**: Process 5 support tickets from a queue, completing all 7 steps for each ticket sequentially.\n",
      "\n",
      "**Tickets Completed: 3 of 5**\n",
      "\n",
      "### Completed Tickets:\n",
      "\n",
      "**TICKET-1** (Alex Davis) - ‚úÖ COMPLETE\n",
      "- Issue: Password reset emails not received, wants to change email\n",
      "- Category: account\n",
      "- Priority: high\n",
      "- Team: account-services\n",
      "- All 7 steps completed successfully\n",
      "\n",
      "**TICKET-2** (Chris Brown) - ‚úÖ COMPLETE\n",
      "- Issue: Cannot update credit card information, getting error messages\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- All 7 steps completed successfully\n",
      "\n",
      "**TICKET-3** (Morgan Smith) - ‚ö†Ô∏è IN PROGRESS\n",
      "- Issue: Never received verification email for new account, blocking premium features\n",
      "- Category: account (classified)\n",
      "- Current status: Completed steps 1-3 (fetch, classify, research)\n",
      "- **Next steps needed**: Steps 4-7 (set priority, route to team, draft response, mark complete)\n",
      "\n",
      "### Remaining Work:\n",
      "1. **Complete TICKET-3**: Need to complete steps 4-7\n",
      "   - Set priority (likely high due to blocked access)\n",
      "   - Route to account-services team\n",
      "   - Draft response using KB info about emails from noreply@support.example.com\n",
      "   - Mark complete\n",
      "2. **Process TICKET-4**: Fetch and complete all 7 steps\n",
      "3. **Process TICKET-5**: Fetch and complete all 7 steps\n",
      "\n",
      "### Key Learnings:\n",
      "- KB search for account issues returns: password reset info, 2FA backup codes, email change verification\n",
      "- KB search for billing issues returns: refund policy, payment methods (Visa/MC/Amex/PayPal), billing cycle info\n",
      "- Email verification likely uses same noreply@support.example.com address as password resets\n",
      "- Priority levels used so far: high (for access-blocking issues)\n",
      "- Teams identified: account-services, billing-team\n",
      "\n",
      "### Process Reminder:\n",
      "Each ticket requires ALL 7 steps in order: fetch ‚Üí classify ‚Üí research ‚Üí prioritize ‚Üí route ‚Üí draft ‚Üí complete\n",
      "</summary>\n",
      "\n",
      "============================================================\n",
      "Turn 18: Input=  1,773 tokens | Output=  460 tokens | Messages= 1 | Cumulative In=  57,032\n",
      "Turn 19: Input=  2,599 tokens | Output=   78 tokens | Messages= 3 | Cumulative In=  59,631\n",
      "Turn 20: Input=  2,853 tokens | Output=  164 tokens | Messages= 5 | Cumulative In=  62,484\n",
      "Turn 21: Input=  3,466 tokens | Output=  444 tokens | Messages= 7 | Cumulative In=  65,950\n",
      "Turn 22: Input=  4,277 tokens | Output=   70 tokens | Messages= 9 | Cumulative In=  70,227\n",
      "Turn 23: Input=  4,517 tokens | Output=  162 tokens | Messages=11 | Cumulative In=  74,744\n",
      "Turn 24: Input=  4,986 tokens | Output=  458 tokens | Messages=13 | Cumulative In=  79,730\n",
      "\n",
      "============================================================\n",
      "üîÑ Compaction occurred! Messages: 13 ‚Üí 1\n",
      "   Summary message after compaction:\n",
      "<summary>\n",
      "## Task Completion Summary\n",
      "\n",
      "**Overall Task**: Process 5 support tickets from a queue, completing all 7 steps for each ticket sequentially.\n",
      "\n",
      "**STATUS: ‚úÖ ALL 5 TICKETS COMPLETED SUCCESSFULLY**\n",
      "\n",
      "### Completed Tickets:\n",
      "\n",
      "**TICKET-1** (Alex Davis) - ‚úÖ COMPLETE\n",
      "- Issue: Password reset emails not received, wants to change email\n",
      "- Category: account\n",
      "- Priority: high\n",
      "- Team: account-services\n",
      "- All 7 steps completed successfully\n",
      "\n",
      "**TICKET-2** (Chris Brown) - ‚úÖ COMPLETE\n",
      "- Issue: Cannot update credit card information, getting error messages\n",
      "- Category: billing\n",
      "- Priority: high\n",
      "- Team: billing-team\n",
      "- All 7 steps completed successfully\n",
      "\n",
      "**TICKET-3** (Morgan Smith) - ‚úÖ COMPLETE\n",
      "- Issue: Never received verification email for new account, blocking premium features\n",
      "- Category: account\n",
      "- Priority: high\n",
      "- Team: account-services\n",
      "- Completed steps 4-7 in this session (prioritize, route, draft, complete)\n",
      "- Response referenced noreply@support.example.com for verification emails\n",
      "\n",
      "**TICKET-4** (Alex Williams) - ‚úÖ COMPLETE\n",
      "- Issue: App crashes after v5.2.9 update on MacBook Pro (subject mentioned \"Export feature not working\" but description was about crashes)\n",
      "- Category: technical\n",
      "- Priority: high\n",
      "- Team: tech-support\n",
      "- All 7 steps completed in this session\n",
      "- Response included troubleshooting steps: clear cache, check system requirements, disable VPN, enable JavaScript\n",
      "\n",
      "**TICKET-5** (John Williams) - ‚úÖ COMPLETE\n",
      "- Issue: Needs to change email from old950@example.com to new967@example.com, no access to old email (subject mentioned \"Two-factor authentication issues\" but description was about email change)\n",
      "- Category: account\n",
      "- Priority: high\n",
      "- Team: account-services\n",
      "- All 7 steps completed in this session\n",
      "- Response noted email changes require verification of both addresses, but alternative identity verification needed when old email inaccessible\n",
      "\n",
      "### Process Applied (7 Steps per Ticket):\n",
      "1. **Fetch** - get_next_ticket()\n",
      "2. **Classify** - classify_ticket() with category\n",
      "3. **Research** - search_knowledge_base() for relevant info\n",
      "4. **Prioritize** - set_priority() (used \"high\" for all access-blocking issues)\n",
      "5. **Route** - route_to_team() to appropriate team\n",
      "6. **Draft** - draft_response() with helpful, personalized response\n",
      "7. **Complete** - mark_complete() to resolve ticket\n",
      "\n",
      "### Teams Used:\n",
      "- **account-services**: Account access, email changes, verification emails, 2FA issues\n",
      "- **billing-team**: Payment processing, credit card issues, billing cycles\n",
      "- **tech-support**: Technical issues, app crashes, troubleshooting\n",
      "\n",
      "### Knowledge Base Insights:\n",
      "- **Account category**: Password resets from noreply@support.example.com (1hr expiry), 2FA backup codes (one-time use), email changes require dual verification\n",
      "- **Billing category**: Refund policy (30 days, original payment method), accepted payments (Visa/MC/Amex/PayPal), billing cycles (monthly/annual)\n",
      "- **Technical category**: Common errors (connection timeout, file size 100MB limit, supported formats), system requirements (4GB RAM, modern browsers), troubleshooting (clear cache, incognito mode, enable JavaScript)\n",
      "\n",
      "### Key Learnings:\n",
      "- Several tickets had mismatched subjects vs descriptions - addressed both in responses\n",
      "- All tickets were marked \"high\" priority as they involved access-blocking or critical functionality issues\n",
      "- Responses personalized with customer names and specific details from their tickets\n",
      "- KB search results consistently provided relevant troubleshooting information\n",
      "\n",
      "### Task Status:\n",
      "**COMPLETE** - All 5 tickets have been processed through all 7 required steps. No further action needed.\n",
      "</summary>\n",
      "\n",
      "============================================================\n",
      "Turn 25: Input=  2,173 tokens | Output=  342 tokens | Messages= 1 | Cumulative In=  81,903\n",
      "\n",
      "============================================================\n",
      "OPTIMIZED RESULTS (WITH COMPACTION)\n",
      "============================================================\n",
      "Total turns:   25\n",
      "Compactions:   2\n",
      "Input tokens:  81,903\n",
      "Output tokens: 3,999\n",
      "Total tokens:  85,902\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize queue and run with compaction\n",
    "initialize_ticket_queue(num_tickets)\n",
    "\n",
    "total_input_compact = 0\n",
    "total_output_compact = 0\n",
    "turn_count_compact = 0\n",
    "compaction_count = 0\n",
    "prev_msg_count = 0\n",
    "\n",
    "runner = client.beta.messages.tool_runner(\n",
    "    model=MODEL,\n",
    "    max_tokens=4096,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    "    compaction_control={\n",
    "        \"enabled\": True,\n",
    "        \"context_token_threshold\": 5000,\n",
    "    },\n",
    ")\n",
    "\n",
    "for message in runner:\n",
    "    turn_count_compact += 1\n",
    "    total_input_compact += message.usage.input_tokens\n",
    "    total_output_compact += message.usage.output_tokens\n",
    "    messages_list = list(runner._params[\"messages\"])\n",
    "    curr_msg_count = len(messages_list)\n",
    "\n",
    "    if curr_msg_count < prev_msg_count:\n",
    "        # We can identify compaction when the message count decreases\n",
    "        compaction_count += 1\n",
    "\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"üîÑ Compaction occurred! Messages: {prev_msg_count} ‚Üí {curr_msg_count}\")\n",
    "        print(\"   Summary message after compaction:\")\n",
    "        print(messages_list[-1]['content'][-1].text)    # type: ignore\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "\n",
    "    prev_msg_count = curr_msg_count\n",
    "    print(\n",
    "            f\"Turn {turn_count_compact:2d}: Input={message.usage.input_tokens:7,} tokens | \"\n",
    "            f\"Output={message.usage.output_tokens:5,} tokens | \"\n",
    "            f\"Messages={len(messages_list):2d} | \"\n",
    "            f\"Cumulative In={total_input_compact:8,}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"OPTIMIZED RESULTS (WITH COMPACTION)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Total turns:   {turn_count_compact}\")\n",
    "print(f\"Compactions:   {compaction_count}\")\n",
    "print(f\"Input tokens:  {total_input_compact:,}\")\n",
    "print(f\"Output tokens: {total_output_compact:,}\")\n",
    "print(f\"Total tokens:  {total_input_compact + total_output_compact:,}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbfe32",
   "metadata": {},
   "source": [
    "With automatic context compaction enabled, we can see that our token usage per turn does not grow linearly, but is reduced after each compaction event. There were two compaction events during the processing of tickets, and the follow turn shows a reduction in total token usage.\n",
    "\n",
    "Compared to the baseline version, we only used 79,000 tokens. We've also printed out the summary messages generated after each compaction event, showing how Claude effectively condensed prior ticket details into summaries.\n",
    "\n",
    "Let's look at the final response after processing all 5 tickets with compaction enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24dd5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing this comprehensive summary! I can see that you've successfully completed processing all 5 support tickets through the entire 7-step workflow.\n",
      "\n",
      "## Summary Confirmation ‚úÖ\n",
      "\n",
      "**Task Status: COMPLETE**\n",
      "\n",
      "All 5 tickets have been fully processed:\n",
      "1. ‚úÖ TICKET-1 (Alex Davis) - Account issues\n",
      "2. ‚úÖ TICKET-2 (Chris Brown) - Billing issues  \n",
      "3. ‚úÖ TICKET-3 (Morgan Smith) - Account verification\n",
      "4. ‚úÖ TICKET-4 (Alex Williams) - Technical/app crashes\n",
      "5. ‚úÖ TICKET-5 (John Williams) - Account email change\n",
      "\n",
      "Each ticket went through all 7 required steps:\n",
      "- Fetch ‚Üí Classify ‚Üí Research ‚Üí Prioritize ‚Üí Route ‚Üí Draft ‚Üí Complete\n",
      "\n",
      "## Key Highlights:\n",
      "\n",
      "- **Consistent categorization**: Properly distributed across account-services (3), billing-team (1), and tech-support (1)\n",
      "- **Appropriate prioritization**: All marked as \"high\" due to access-blocking nature\n",
      "- **Knowledge base utilization**: Effectively researched relevant information for each category\n",
      "- **Quality responses**: Personalized, addressed subject/description mismatches when present\n",
      "\n",
      "The workflow has been executed systematically and thoroughly. No additional tickets remain in the queue, and all processed tickets are ready for team review.\n",
      "\n",
      "Is there anything specific about the completed tickets you'd like to review, or any patterns you noticed that might improve future ticket processing?\n"
     ]
    }
   ],
   "source": [
    "print(message.content[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vb4cesnmb8",
   "metadata": {},
   "source": [
    "### Comparing Results\n",
    "\n",
    "With compaction enabled, we can see a clear differece between the two runs in token savings, while preserving the quality of the workflow and final summary.\n",
    "\n",
    "Here's what changed with automatic context compaction:\n",
    "\n",
    "1. **Context resets after several tickets** - When processing 5-7 tickets generates 5k+ tokens of tool results, the SDK automatically:\n",
    "   - Injects a summary prompt\n",
    "   - Has Claude generate a completion summary wrapped in `<summary></summary>` tags\n",
    "   - Clears the conversation history and discards detailed classifications, KB searches, and responses\n",
    "   - Continues with only the completion summary\n",
    "\n",
    "2. **Input tokens stay bounded** - Instead of accumulating to 100k+ as we process more tickets, input tokens reset after each compaction. When processing Ticket #5, we're NOT carrying the full tool results from Tickets #1-4.\n",
    "\n",
    "3. **Task completes successfully** - The workflow continues smoothly through all tickets without hitting context limits\n",
    "\n",
    "4. **Quality is preserved** - The summaries retain critical information:\n",
    "   - Tickets processed with their IDs\n",
    "   - Categories and priorities assigned\n",
    "   - Teams routed to\n",
    "   - Overall progress status\n",
    "   \n",
    "   All tickets are still properly classified, prioritized, routed, and responded to.\n",
    "\n",
    "5. **Natural workflow** - This mirrors how real support agents work: resolve a ticket, document it briefly in the system, close it, move to the next one. You don't keep every knowledge base article and full response draft open while working on new tickets.\n",
    "\n",
    "Let's visualize the token savings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "z9lvigc94p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOKEN USAGE COMPARISON\n",
      "======================================================================\n",
      "Metric                         Baseline             With Compaction     \n",
      "----------------------------------------------------------------------\n",
      "Input tokens:                              150,881              81,903\n",
      "Output tokens:                               3,902               3,999\n",
      "Total tokens:                              154,783              85,902\n",
      "Compactions:                                   N/A                   2\n",
      "======================================================================\n",
      "\n",
      "üí∞ Token Savings: 68,881 tokens (44.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Compare baseline vs compaction\n",
    "print(\"=\" * 70)\n",
    "print(\"TOKEN USAGE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<30} {'Baseline':<20} {'With Compaction':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Input tokens:':<30} {total_input:>19,} {total_input_compact:>19,}\")\n",
    "print(f\"{'Output tokens:':<30} {total_output:>19,} {total_output_compact:>19,}\")\n",
    "print(\n",
    "    f\"{'Total tokens:':<30} {total_input + total_output:>19,} {total_input_compact + total_output_compact:>19,}\"\n",
    ")\n",
    "print(f\"{'Compactions:':<30} {'N/A':>19} {compaction_count:>19}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate savings\n",
    "token_savings = (total_input + total_output) - (total_input_compact + total_output_compact)\n",
    "savings_percent = (\n",
    "    (token_savings / (total_input + total_output)) * 100 if (total_input + total_output) > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"\\nüí∞ Token Savings: {token_savings:,} tokens ({savings_percent:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lzvf1mw7o6",
   "metadata": {},
   "source": [
    "## How Compaction Works Under the Hood\n",
    "\n",
    "When the `tool_runner` detects that token usage has exceeded the threshold, it automatically:\n",
    "\n",
    "1. **Pauses the workflow** before making the next API call\n",
    "2. **Injects a summary request** as a user message asking Claude to summarize progress\n",
    "3. **Generates a summary** - Claude produces a summary wrapped in `<summary></summary>` tags containing:\n",
    "   - **Completed tickets**: Brief records of tickets resolved (IDs, categories, priorities, outcomes)\n",
    "   - **Progress status**: How many tickets processed, how many remain\n",
    "   - **Key patterns**: Any notable trends across tickets\n",
    "   - **Next steps**: What to do next (continue processing remaining tickets)\n",
    "4. **Clears history** - The entire conversation history (including all tool results) is replaced with just the summary\n",
    "5. **Resumes processing** - Claude continues working with the compressed context, processing the next batch of tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v64ljd0a79",
   "metadata": {},
   "source": [
    "## Customizing Compaction Configuration\n",
    "\n",
    "You can customize how compaction works to fit your specific use case. Here are the key configuration options:\n",
    "\n",
    "### Adjusting the Threshold\n",
    "\n",
    "The `context_token_threshold` determines when compaction triggers:\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"context_token_threshold\": 5000,  # Compact after processing 5-7 tickets\n",
    "}\n",
    "```\n",
    "\n",
    "The threshold should not be set too low, otherwise the summary itself could trigger a compaction. We set a threshold of 5,000 tokens for demonstration purposes, but in practice, experiment with different settings to find what works best for your workflow.\n",
    "\n",
    "Here some general guidelines:\n",
    "\n",
    "- **Low thresholds (5k-20k)**: \n",
    "  - Use for iterative task processing with clear boundaries\n",
    "  - More frequent compaction, minimal context accumulation\n",
    "  - Best for sequential entity processing\n",
    "  \n",
    "- **Medium thresholds (50k-100k)**: \n",
    "  - Multi-phase workflows with fewer, larger natural checkpoints\n",
    "  - Balance between context retention and management\n",
    "  - Suitable for workflows with expensive tool calls\n",
    "  \n",
    "- **High thresholds (100k-150k)**: \n",
    "  - Tasks requiring substantial historical context\n",
    "  - Less frequent compaction preserves more raw details\n",
    "  - Higher per-call costs but fewer compactions\n",
    "  \n",
    "- **Default (150k)**: Good balance for general long-running tasks\n",
    "\n",
    "**For ticket processing**: The 5k threshold works well because each ticket's workflow generates substantial tool results, but tickets are independent. After resolving Ticket A, you don't need its detailed KB searches when processing Ticket B.\n",
    "\n",
    "### Using a Different Model for Summarization\n",
    "\n",
    "You can also use a faster/cheaper model for generating summaries:\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"model\": \"claude-haiku-4-5\",  # Use Haiku for cost-effective summaries\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w4oyvorzkn",
   "metadata": {},
   "source": [
    "### Custom Summary Prompts\n",
    "\n",
    "You can provide a custom prompt to guide how summaries are generated. This is especially useful for customer service workflows where you need to preserve specific types of information.\n",
    "\n",
    "For example, we could define a custom prompt based on our requirements:\n",
    "- **Ticket summaries** for all completed tickets\n",
    "- **Categories and priorities** assigned\n",
    "- **Teams routed to**\n",
    "- **Progress status** (tickets completed, tickets remaining)\n",
    "- **Next steps** in the workflow\n",
    "\n",
    "```python\n",
    "compaction_control={\n",
    "    \"enabled\": True,\n",
    "    \"summary_prompt\": \"\"\"You are processing customer support tickets from a queue.\n",
    "\n",
    "Create a focused summary that preserves:\n",
    "\n",
    "1. **COMPLETED TICKETS**: For each ticket you've fully processed:\n",
    "   - Ticket ID and customer name\n",
    "   - Issue category and priority assigned\n",
    "   - Team routed to\n",
    "   - Brief outcome\n",
    "\n",
    "2. **PROGRESS STATUS**: \n",
    "   - How many tickets you've completed\n",
    "   - Approximately how many remain in the queue\n",
    "\n",
    "3. **NEXT STEPS**: Continue processing the next ticket\n",
    "\n",
    "Format with clear sections and wrap in <summary></summary> tags.\"\"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dwo1dayp",
   "metadata": {},
   "source": [
    "## Limitations and Considerations\n",
    "\n",
    "While automatic context compaction is powerful, there are important limitations to understand:\n",
    "\n",
    "### Server-Side Sampling Loops\n",
    "\n",
    "**Current Limitation**: Compaction does not work optimally with server-side sampling loops, such as server-side web search tools.\n",
    "\n",
    "**Why**: Cache tokens accumulate across sampling loops, which can trigger compaction prematurely based on cached content rather than actual conversation history.\n",
    "\n",
    "This feature works best with:\n",
    "- ‚úÖ Client-side tools (like the customer service API in this cookbook)\n",
    "- ‚úÖ Standard agentic workflows with regular tool use\n",
    "- ‚úÖ File operations, database queries, API calls\n",
    "- ‚ùå Server-side Extended Thinking\n",
    "- ‚ùå Server-side web search tools\n",
    "\n",
    "### Information Loss\n",
    "\n",
    "**Trade-off**: Summaries inherently lose some information. While Claude is good at identifying key points, some details will be compressed or omitted.\n",
    "\n",
    "**In ticket processing**: \n",
    "- ‚úÖ **Retained**: Ticket IDs, categories, priorities, teams, outcomes, progress status\n",
    "- ‚ùå **Lost**: Full knowledge base article text, complete drafted response text, detailed classification reasoning\n",
    "\n",
    "This is usually acceptable, you don't need every KB article and full response text in perpetuity, just the completion records.\n",
    "\n",
    "**Mitigation**:\n",
    "- Use custom summary prompts to preserve critical information\n",
    "- Set higher thresholds for tasks requiring extensive historical context\n",
    "- Structure your tasks to be modular (each phase builds on summaries, not raw details)\n",
    "\n",
    "### When NOT to Use Compaction\n",
    "\n",
    "Avoid compaction for:\n",
    "\n",
    "1. **Short tasks**: If your task completes within 50k-100k tokens, compaction adds unnecessary overhead\n",
    "2. **Tasks requiring full audit trails**: Some tasks need access to ALL previous details\n",
    "3. **Server-side sampling workflows**: As mentioned above, wait for this limitation to be addressed\n",
    "4. **Highly iterative refinement**: Tasks where each step critically depends on exact details from all previous steps\n",
    "\n",
    "### When TO Use Compaction\n",
    "\n",
    "Compaction is ideal for:\n",
    "\n",
    "1. **Sequential processing**: Like our ticket workflow‚Äîprocess multiple items one after another\n",
    "2. **Multi-phase workflows**: Where each phase can summarize progress before moving on\n",
    "3. **Iterative data processing**: Processing large datasets in chunks or entities one at a time\n",
    "4. **Extended analysis sessions**: Analyzing data across many entities\n",
    "5. **Batch operations**: Processing hundreds of items where each is independent\n",
    "\n",
    "**Ticket processing is a perfect use case** because:\n",
    "- Each ticket workflow is largely independent\n",
    "- You need completion summaries, not full tool results\n",
    "- Natural compaction points exist (after completing several tickets)\n",
    "- The workflow is iterative and sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4pz1jmdidi",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Automatic context compaction is a powerful feature that enables long-running agentic workflows to exceed typical context limits. In this cookbook, we've explored compaction through a customer service ticket processing workflow.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Try implementing compaction in your own workflows:\n",
    "1. Identify natural compaction points (after processing each item, completing each phase, etc.)\n",
    "2. Start with an aggressive threshold (5k-10k) if you have clear per-item boundaries\n",
    "3. Use custom summary prompts to preserve critical information\n",
    "4. Monitor when compaction triggers and verify quality is maintained\n",
    "5. Adjust threshold based on your specific needs\n",
    "\n",
    "For more on effective context management, see [Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anthropic-cookbook (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
